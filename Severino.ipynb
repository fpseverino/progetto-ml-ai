{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fpseverino/progetto-ml-ai/blob/main/Severino.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "dLf35CffNFTo"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "import pandas as pd\n",
        "import copy\n",
        "from scipy import stats\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "from sklearn.experimental import enable_halving_search_cv\n",
        "from sklearn.model_selection import train_test_split, HalvingGridSearchCV, cross_val_score\n",
        "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, HistGradientBoostingClassifier\n",
        "from sklearn.neural_network import MLPClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classe Task\n",
        "Viene definita una classe `Task`, che viene inizializzata a partire da un `DataFrame` e ha come attributi `X`, `y` e le loro suddivisioni per il training e il testing.\n",
        "\n",
        "La classe contiene anche un metodo per scalare l'`X` con uno specifico scaler."
      ],
      "metadata": {
        "id": "vyzZnl7sx9mR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Task:\n",
        "  def __init__(self, df):\n",
        "    X = df.drop(\"Label\", axis = 1)\n",
        "    X = X.drop(\"Task\", axis = 1)\n",
        "    X = X.drop(\"Id\", axis = 1)\n",
        "    y = df[\"Label\"]\n",
        "\n",
        "    self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
        "\n",
        "  def scale(self, sc):\n",
        "    sc.fit(self.X_train)\n",
        "    self.X_train = sc.transform(self.X_train)\n",
        "    self.X_test = sc.transform(self.X_test)"
      ],
      "metadata": {
        "id": "9IkqpWEFh13q"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Di seguito vengono letti i `csv` dei Task già ripuliti e vengono salvati come oggetti `Task` all'interno dell'array `tasks`."
      ],
      "metadata": {
        "id": "dJilUGyXydfq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tasks = []\n",
        "for i in range(11, 22):\n",
        "  df = pd.read_csv(\"Task_{}_clean.csv\".format(i))\n",
        "  task = Task(df)\n",
        "  tasks.append(task)"
      ],
      "metadata": {
        "id": "S_RmKKO-Qz4H"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Di seguito viene calcolata la moda delle lable del set di testing e viene definita una funzione per calcolarne la somiglianza con i risultati delle predizioni."
      ],
      "metadata": {
        "id": "Wo8zB1se2Vut"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_tests = []\n",
        "for task in tasks:\n",
        "  y_tests.append(copy.deepcopy(task.y_test))\n",
        "\n",
        "y_test_mode, y_test_count = stats.mode(y_tests)\n",
        "\n",
        "def similarity(predictions_mode):\n",
        "  if len(y_test_mode) != len(predictions_mode):\n",
        "    return 0.0\n",
        "\n",
        "  correct = 0\n",
        "  for i in range(len(predictions_mode)):\n",
        "    if y_test_mode[i] == predictions_mode[i]:\n",
        "      correct += 1\n",
        "\n",
        "  return correct / len(predictions_mode)"
      ],
      "metadata": {
        "id": "0Wtpe_JCleD2"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Funzione `test_boosting`\n",
        "Dopo aver eventualmente scalato i `Task` mediante uno scaler, viene eseguito, task per task, un fit del classificatore, e vengono salvati gli score e le predizioni, di cui verranno stampati rispettivamente la media e la moda."
      ],
      "metadata": {
        "id": "IQaJFG_II9ky"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_boosting(clf, sc = None):\n",
        "  test_tasks = copy.deepcopy(tasks)\n",
        "\n",
        "  if sc is not None:\n",
        "    for task in test_tasks:\n",
        "      task.scale(sc)\n",
        "\n",
        "  cross_val_scores = []\n",
        "  scores = []\n",
        "  predictions = []\n",
        "\n",
        "  for task in test_tasks:\n",
        "    cross_val_scores.append(cross_val_score(clf, task.X_train, task.y_train, n_jobs = -1).mean())\n",
        "    clf.fit(task.X_train, task.y_train)\n",
        "    scores.append(clf.score(task.X_test, task.y_test))\n",
        "    predictions.append(clf.predict(task.X_test))\n",
        "\n",
        "  print(\"Results{}:\".format(\"\" if sc is None else \" (scaled tasks)\"))\n",
        "  print(\" - Mean cross_val_score: {:.2%}\".format(np.mean(cross_val_scores)))\n",
        "  print(\" - Mean score:           {:.2%}\".format(np.mean(scores)))\n",
        "\n",
        "  mode, count = stats.mode(predictions)\n",
        "  print(\" - Similarity:           {:.2%}\\n\".format(similarity(mode)))"
      ],
      "metadata": {
        "id": "Ly_dI5yqIDtg"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classificatore `AdaBoost`\n",
        "Un classificatore AdaBoost è un meta-stimatore che inizia inserendo un classificatore nel set di dati originale e quindi adatta copie aggiuntive del classificatore nello stesso set di dati, ma dove i pesi delle istanze classificate in modo errato vengono regolati in modo tale che i classificatori successivi si concentrino maggiormente sui casi difficili."
      ],
      "metadata": {
        "id": "XS_RmX3-yppQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf = AdaBoostClassifier(n_estimators = 100, random_state = 0)\n",
        "sc = MinMaxScaler(feature_range = (0, 1))\n",
        "test_boosting(clf)\n",
        "test_boosting(clf, sc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "na_GntyGVI-2",
        "outputId": "72f2df85-25e2-41a1-8f6b-5c1211b5198e"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results:\n",
            " - Mean cross_val_score: 74.68%\n",
            " - Mean score:           79.04%\n",
            " - Similarity:           83.33%\n",
            "\n",
            "Results (scaled tasks):\n",
            " - Mean cross_val_score: 76.62%\n",
            " - Mean score:           82.58%\n",
            " - Similarity:           77.78%\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classificatore Gradient Boosting\n",
        "\n",
        "Questo algoritmo costruisce un modello additivo in modo graduale; consente l'ottimizzazione di funzioni di perdita differenziabili arbitrarie. In ogni fase, `n_classes_` alberi di regressione sono adattati al gradiente negativo della funzione di perdita, ad es. perdita di log binaria o multiclasse."
      ],
      "metadata": {
        "id": "yd2IwTPKk_hb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf = GradientBoostingClassifier(n_estimators = 500, learning_rate = 0.01, random_state = 0)\n",
        "sc = MinMaxScaler(feature_range = (0, 1))\n",
        "test_boosting(clf)\n",
        "test_boosting(clf, sc)"
      ],
      "metadata": {
        "id": "KwDM-PQplFiE",
        "outputId": "05db7d4c-7df5-4046-e958-abc6139857ed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results:\n",
            " - Mean cross_val_score: 83.50%\n",
            " - Mean score:           87.63%\n",
            " - Similarity:           77.78%\n",
            "\n",
            "Results (scaled tasks):\n",
            " - Mean cross_val_score: 86.03%\n",
            " - Mean score:           87.12%\n",
            " - Similarity:           86.11%\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Albero di classificazione Gradient Boosting basato sugli istogrammi\n",
        "Questo stimatore ha il supporto nativo per i valori mancanti (`NaN`). Durante l'addestramento, il coltivatore di alberi impara ad ogni punto di divisione se i campioni con valori mancanti devono andare al figlio sinistro o destro, in base al potenziale guadagno. Durante la previsione, i campioni con valori mancanti vengono assegnati di conseguenza al figlio sinistro o destro. Se durante l'addestramento non sono stati rilevati valori mancanti per una determinata funzionalità, i campioni con valori mancanti vengono mappati a qualunque figlio abbia il maggior numero di campioni."
      ],
      "metadata": {
        "id": "W8OlNRpf0nxa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf = HistGradientBoostingClassifier(learning_rate = 0.01, random_state = 0)\n",
        "sc = MinMaxScaler(feature_range = (0, 1))\n",
        "test_boosting(clf)\n",
        "test_boosting(clf, sc)"
      ],
      "metadata": {
        "id": "gIejO21GhzxD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classificatore Percettrone multi-strato\n",
        "Vengono scalati i task tramite uno `StandardScaler`, in seguito viene eseguita una ricerca sui parametri forniti, e viene testato su tutti i task un `MLPCLassifier` con i parametri migliori.\n",
        "\n",
        "Infine viene raccolta la predizione per ogni sample del testing per ogni task, viene calcolata la moda attraverso tutti i task per ogni sample e viene stampata a schermo."
      ],
      "metadata": {
        "id": "zWQoreTm1JnL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sc = StandardScaler()\n",
        "\n",
        "scaled_tasks = copy.deepcopy(tasks)\n",
        "\n",
        "for task in scaled_tasks:\n",
        "  task.scale(sc)\n",
        "\n",
        "param_grid = {\n",
        "  \"hidden_layer_sizes\": [(150, 100, 50), (120, 80, 40), (100, 50, 30)],\n",
        "  \"activation\": ['identity', 'logistic', 'tanh', 'relu'],\n",
        "  \"solver\": ['lbfgs', 'sgd', 'adam'],\n",
        "  \"alpha\": [0.0001, 0.001, 0.01, 0.1, 1, 10, 100],\n",
        "  \"learning_rate\": ['constant', 'invscaling', 'adaptive'],\n",
        "  \"max_iter\": [1000, 2000, 3000]\n",
        "}\n",
        "search = HalvingGridSearchCV(MLPClassifier(random_state = 0), param_grid, n_jobs = -1)\n",
        "\n",
        "cross_val_scores = []\n",
        "scores = []\n",
        "predictions = []\n",
        "\n",
        "for task in scaled_tasks:\n",
        "  search.fit(task.X_train, task.y_train)\n",
        "\n",
        "  clf = MLPClassifier(**search.best_params_, random_state = 0)\n",
        "\n",
        "  cross_val_scores.append(cross_val_score(clf, task.X_train, task.y_train, n_jobs = -1).mean())\n",
        "  clf.fit(task.X_train, task.y_train)\n",
        "  scores.append(clf.score(task.X_test, task.y_test))\n",
        "  predictions.append(clf.predict(task.X_test))\n",
        "\n",
        "print(\"Results (scaled tasks):\")\n",
        "print(\" - Mean cross_val_score: {:.2%}\".format(np.mean(cross_val_scores)))\n",
        "print(\" - Mean score:           {:.2%}\".format(np.mean(scores)))\n",
        "\n",
        "mode, count = stats.mode(predictions)\n",
        "print(\" - Similarity:           {:.2%}\\n\".format(similarity(mode)))"
      ],
      "metadata": {
        "id": "x2qjfpb8qUva"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}