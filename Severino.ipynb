{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fpseverino/progetto-ml-ai/blob/main/Severino.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "dLf35CffNFTo"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "import pandas as pd\n",
        "import copy\n",
        "from scipy import stats\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "from sklearn.experimental import enable_halving_search_cv\n",
        "from sklearn.model_selection import train_test_split, HalvingGridSearchCV, cross_val_score\n",
        "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, HistGradientBoostingClassifier\n",
        "from sklearn.neural_network import MLPClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classe Task\n",
        "Viene definita una classe `Task`, che viene inizializzata a partire da un `DataFrame` e ha come attributi `X`, `y` e le loro suddivisioni per il training e il testing.\n",
        "\n",
        "La classe contiene anche un metodo per scalare l'`X` con uno specifico scaler."
      ],
      "metadata": {
        "id": "vyzZnl7sx9mR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Task:\n",
        "  def __init__(self, df):\n",
        "    X = df.drop(\"Label\", axis = 1)\n",
        "    X = X.drop(\"Task\", axis = 1)\n",
        "    X = X.drop(\"Id\", axis = 1)\n",
        "    y = df[\"Label\"]\n",
        "\n",
        "    self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)\n",
        "\n",
        "  def scale(self, sc):\n",
        "    sc.fit(self.X_train)\n",
        "    self.X_train = sc.transform(self.X_train)\n",
        "    self.X_test = sc.transform(self.X_test)"
      ],
      "metadata": {
        "id": "9IkqpWEFh13q"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Di seguito vengono letti i `csv` dei Task già ripuliti e vengono salvati come oggetti `Task` all'interno dell'array `tasks`."
      ],
      "metadata": {
        "id": "dJilUGyXydfq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tasks = []\n",
        "for i in range(11, 22):\n",
        "  df = pd.read_csv(\"Task_{}_clean.csv\".format(i))\n",
        "  task = Task(df)\n",
        "  tasks.append(task)"
      ],
      "metadata": {
        "id": "S_RmKKO-Qz4H"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Di seguito viene calcolata la moda delle lable del set di testing e viene definita una funzione per calcolarne la somiglianza con i risultati delle predizioni."
      ],
      "metadata": {
        "id": "Wo8zB1se2Vut"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_tests = []\n",
        "for task in tasks:\n",
        "  y_tests.append(copy.deepcopy(task.y_test))\n",
        "\n",
        "y_test_mode, y_test_count = stats.mode(y_tests)\n",
        "\n",
        "def similarity(predictions_mode):\n",
        "  if len(y_test_mode) != len(predictions_mode):\n",
        "    return 0.0\n",
        "\n",
        "  correct = 0\n",
        "  for i in range(len(predictions_mode)):\n",
        "    if y_test_mode[i] == predictions_mode[i]:\n",
        "      correct += 1\n",
        "\n",
        "  return correct / len(predictions_mode)"
      ],
      "metadata": {
        "id": "0Wtpe_JCleD2"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Funzione `test_boosting`\n",
        "Dopo aver eventualmente scalato i `Task` mediante uno scaler, viene eseguito, task per task, un fit del classificatore, e vengono salvati gli score e le predizioni, di cui verranno stampati rispettivamente la media e la moda."
      ],
      "metadata": {
        "id": "IQaJFG_II9ky"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_boosting(clf, sc = None):\n",
        "  test_tasks = copy.deepcopy(tasks)\n",
        "\n",
        "  if sc is not None:\n",
        "    print(\"Scaled results:\")\n",
        "    for task in test_tasks:\n",
        "      task.scale(sc)\n",
        "  else:\n",
        "    print(\"Results:\")\n",
        "\n",
        "  cross_val_scores = []\n",
        "  scores = []\n",
        "  predictions = []\n",
        "\n",
        "  for task in test_tasks:\n",
        "    cross_val_scores.append(cross_val_score(clf, task.X_train, task.y_train, cv = 3, n_jobs = -1).mean())\n",
        "    clf.fit(task.X_train, task.y_train)\n",
        "    scores.append(clf.score(task.X_test, task.y_test))\n",
        "    predictions.append(clf.predict(task.X_test))\n",
        "\n",
        "  print(\" - Mean cross_val_score: {:.2%}\".format(np.mean(cross_val_scores)))\n",
        "  print(\" - Mean score: {:.2%}\".format(np.mean(scores)))\n",
        "\n",
        "  mode, count = stats.mode(predictions)\n",
        "  print(\" - Similarity: {:.2%}\\n\".format(similarity(mode)))"
      ],
      "metadata": {
        "id": "Ly_dI5yqIDtg"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classificatore `AdaBoost`\n",
        "Un classificatore AdaBoost è un meta-stimatore che inizia inserendo un classificatore nel set di dati originale e quindi adatta copie aggiuntive del classificatore nello stesso set di dati, ma dove i pesi delle istanze classificate in modo errato vengono regolati in modo tale che i classificatori successivi si concentrino maggiormente sui casi difficili."
      ],
      "metadata": {
        "id": "XS_RmX3-yppQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf = AdaBoostClassifier(n_estimators = 100, random_state = 0)\n",
        "sc = MinMaxScaler(feature_range = (0, 1))\n",
        "test_boosting(clf)\n",
        "test_boosting(clf, sc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "na_GntyGVI-2",
        "outputId": "b4dc1f76-671b-4384-8323-489095321487"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results:\n",
            " - Mean cross_val_score: 73.17%\n",
            " - Mean score: 79.04%\n",
            " - Similarity: 83.33%\n",
            "\n",
            "Scaled results:\n",
            " - Mean cross_val_score: 73.83%\n",
            " - Mean score: 82.58%\n",
            " - Similarity: 77.78%\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classificatore Gradient Boosting\n",
        "\n",
        "Questo algoritmo costruisce un modello additivo in modo graduale; consente l'ottimizzazione di funzioni di perdita differenziabili arbitrarie. In ogni fase, `n_classes_` alberi di regressione sono adattati al gradiente negativo della funzione di perdita, ad es. perdita di log binaria o multiclasse."
      ],
      "metadata": {
        "id": "yd2IwTPKk_hb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf = GradientBoostingClassifier(n_estimators = 500, learning_rate = 0.01, random_state = 0)\n",
        "sc = MinMaxScaler(feature_range = (0, 1))\n",
        "test_boosting(clf)\n",
        "test_boosting(clf, sc)"
      ],
      "metadata": {
        "id": "KwDM-PQplFiE",
        "outputId": "61197320-088f-4b3c-f6fa-a87105f1bea8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results:\n",
            " - Mean cross_val_score: 82.57%\n",
            " - Mean score: 87.63%\n",
            " - Similarity: 77.78%\n",
            "\n",
            "Scaled results:\n",
            " - Mean cross_val_score: 84.57%\n",
            " - Mean score: 87.12%\n",
            " - Similarity: 86.11%\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Albero di classificazione Gradient Boosting basato sugli istogrammi\n",
        "Questo stimatore ha il supporto nativo per i valori mancanti (`NaN`). Durante l'addestramento, il coltivatore di alberi impara ad ogni punto di divisione se i campioni con valori mancanti devono andare al figlio sinistro o destro, in base al potenziale guadagno. Durante la previsione, i campioni con valori mancanti vengono assegnati di conseguenza al figlio sinistro o destro. Se durante l'addestramento non sono stati rilevati valori mancanti per una determinata funzionalità, i campioni con valori mancanti vengono mappati a qualunque figlio abbia il maggior numero di campioni."
      ],
      "metadata": {
        "id": "W8OlNRpf0nxa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf = HistGradientBoostingClassifier(learning_rate = 0.01, random_state = 0)\n",
        "sc = MinMaxScaler(feature_range = (0, 1))\n",
        "test_boosting(clf)\n",
        "test_boosting(clf, sc)"
      ],
      "metadata": {
        "id": "gIejO21GhzxD",
        "outputId": "79c411fa-9ea6-4761-b742-2ad001c26908",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results:\n",
            " - Mean cross_val_score: 81.70%\n",
            " - Mean score: 86.62%\n",
            " - Similarity: 86.11%\n",
            "\n",
            "Scaled results:\n",
            " - Mean cross_val_score: 81.70%\n",
            " - Mean score: 86.62%\n",
            " - Similarity: 86.11%\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classificatore Percettrone multi-strato\n",
        "Vengono scalati i task tramite uno `StandardScaler`, in seguito viene eseguita una ricerca sui parametri forniti, e viene testato su tutti i task un `MLPCLassifier` con i parametri migliori.\n",
        "\n",
        "Infine viene raccolta la predizione per ogni sample del testing per ogni task, viene calcolata la moda attraverso tutti i task per ogni sample e viene stampata a schermo."
      ],
      "metadata": {
        "id": "zWQoreTm1JnL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sc = StandardScaler()\n",
        "scaled_tasks = copy.deepcopy(tasks)\n",
        "for task in scaled_tasks:\n",
        "  task.scale(sc)\n",
        "\n",
        "parametri_mlp = {\n",
        "  'hidden_layer_sizes': [(150, 100, 50), (120, 80, 40), (100, 66, 33)],\n",
        "  'solver': ['lbfgs', 'sgd', 'adam'],\n",
        "  'alpha': [0.0001, 0.1, 100],\n",
        "  'max_iter': [100, 200, 300]\n",
        "}\n",
        "grid_mlp = HalvingGridSearchCV(MLPClassifier(), parametri_mlp, n_jobs = -1, cv = 3, scoring = \"accuracy\")\n",
        "\n",
        "cross_val_scores = []\n",
        "scores = []\n",
        "predictions = []\n",
        "\n",
        "for task in scaled_tasks:\n",
        "  grid_mlp.fit(task.X_train, task.y_train)\n",
        "\n",
        "  clf = MLPClassifier(\n",
        "    hidden_layer_sizes = grid_mlp.best_params_[\"hidden_layer_sizes\"],\n",
        "    solver = grid_mlp.best_params_[\"solver\"],\n",
        "    alpha = grid_mlp.best_params_[\"alpha\"],\n",
        "    max_iter = grid_mlp.best_params_[\"max_iter\"],\n",
        "    random_state = 0\n",
        "  )\n",
        "\n",
        "  cross_val_scores.append(cross_val_score(clf, task.X_train, task.y_train, cv = 3, n_jobs = -1).mean())\n",
        "  clf.fit(task.X_train, task.y_train)\n",
        "  scores.append(clf.score(task.X_test, task.y_test))\n",
        "  predictions.append(clf.predict(task.X_test))\n",
        "\n",
        "print(\"Scaled results:\")\n",
        "print(\" - Mean cross_val_score: {:.2%}\".format(np.mean(cross_val_scores)))\n",
        "print(\" - Mean score: {:.2%}\".format(np.mean(scores)))\n",
        "\n",
        "mode, count = stats.mode(predictions)\n",
        "print(\" - Similarity: {:.2%}\\n\".format(similarity(mode)))"
      ],
      "metadata": {
        "id": "x2qjfpb8qUva",
        "outputId": "c84338ed-20fb-4e16-a6e0-8ddc1b729a18",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scaled results:\n",
            " - Mean cross_val_score: 73.60%\n",
            " - Mean score: 76.52%\n",
            " - Similarity: 69.44%\n",
            "\n"
          ]
        }
      ]
    }
  ]
}